{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOsEkIU+/AgLO7kjZY4R7Qw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dzaja123/titanic-dataset-CPU-GPU-TPU-evaluation/blob/main/titanic_dataset_CPU_GPU_TPU_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import urllib.request\n",
        "import time\n",
        "import psutil"
      ],
      "metadata": {
        "id": "pqOqfr-mHki1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data Function\n",
        "def load_data(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "    except:\n",
        "        print(\"File not found\")\n",
        "        data = None\n",
        "    return data"
      ],
      "metadata": {
        "id": "CPnI4DnEH4_O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Data Function\n",
        "def preprocess_data(data, is_test=False):\n",
        "    # Preprocessing\n",
        "    gender_factorized = data.copy()\n",
        "\n",
        "    # Factorize 'Sex'\n",
        "    gender_factorized['Sex'] = gender_factorized['Sex'].replace(['male', 'female'], [0, 1])\n",
        "\n",
        "    # Factorize 'Embarked'\n",
        "    gender_factorized['Embarked'] = gender_factorized['Embarked'].replace(['S', 'C', 'Q'], [0, 1, 2])\n",
        "\n",
        "    if not is_test:\n",
        "        # Select features for training data\n",
        "        gender_factorized['Survived'] = gender_factorized['Survived'].astype(int)\n",
        "        feature = gender_factorized[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "        feature = feature.dropna()\n",
        "        return feature\n",
        "    else:\n",
        "        # Select features for test data\n",
        "        feature = gender_factorized[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "        feature['Fare'].replace(np.nan, feature['Fare'].median(), inplace=True)\n",
        "        feature['Age'].replace(np.nan, feature['Age'].median(), inplace=True)\n",
        "        # Add a placeholder for 'Survived' column (not used in predictions)\n",
        "        feature.loc[:, 'Survived'] = 0\n",
        "        return feature"
      ],
      "metadata": {
        "id": "QYm-6PNoH6t-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data Function\n",
        "def split_data(feature_data):\n",
        "    # Splitting Data\n",
        "    def split_data_frame(df, frac, axis=0) -> list:\n",
        "        if axis == 0:\n",
        "            threshold = int(df.shape[0] * frac)\n",
        "            part1 = df.iloc[0: threshold, :].reset_index(drop=True)\n",
        "            part2 = df.iloc[threshold:, :].reset_index(drop=True)\n",
        "        elif axis == 1:\n",
        "            threshold = df.shape[1] * frac\n",
        "            part1 = df.iloc[:, 0: threshold].reset_index(drop=True)\n",
        "            part2 = df.iloc[:, threshold:].reset_index(drop=True)\n",
        "        else:\n",
        "            print(\"Key 'axis' is '0' or '1'\")\n",
        "            return [None, None]\n",
        "        return [part1, part2]\n",
        "\n",
        "    splitted = split_data_frame(feature_data, 0.8)\n",
        "    train_data = np.array(splitted[0].iloc[:, 1:])\n",
        "    train_label = np.array(splitted[0].iloc[:, 0])\n",
        "    validation_data = np.array(splitted[1].iloc[:, 1:])\n",
        "    validation_label = np.array(splitted[1].iloc[:, 0])\n",
        "    return train_data, train_label, validation_data, validation_label"
      ],
      "metadata": {
        "id": "7oTmQv4cH9A2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Model Function\n",
        "def build_model():\n",
        "    # Building Model\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "uxuQ0X96H-99"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate on CPU Function\n",
        "def train_evaluate_cpu(train_data, train_label, validation_data, validation_label, epochs=500):\n",
        "    print(\"Training and evaluating on CPU:\")\n",
        "    model_cpu = build_model()\n",
        "    acc, loss = train_model(model_cpu, train_data, train_label, epochs)\n",
        "    print(\"Training Accuracy:\", acc[-1])\n",
        "    print(\"Training Loss:\", loss[-1])\n",
        "\n",
        "    result = evaluate_model(model_cpu, validation_data, validation_label)\n",
        "    print(\"Validation Accuracy:\", result[1])\n",
        "    print(\"Validation Loss:\", result[0])\n",
        "    print(\"------------------------- \\n\")\n",
        "    return model_cpu"
      ],
      "metadata": {
        "id": "Xxpr-hY9IApu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate on GPU Function\n",
        "def train_evaluate_gpu(train_data, train_label, validation_data, validation_label, epochs=500):\n",
        "    print(\"Training and evaluating on GPU:\")\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        model_gpu = build_model()\n",
        "        acc_gpu, loss_gpu = train_model(model_gpu, train_data, train_label, epochs)\n",
        "        print(\"Training Accuracy:\", acc_gpu[-1])\n",
        "        print(\"Training Loss:\", loss_gpu[-1])\n",
        "\n",
        "        result_gpu = evaluate_model(model_gpu, validation_data, validation_label)\n",
        "        print(\"Validation Accuracy:\", result_gpu[1])\n",
        "        print(\"Validation Loss:\", result_gpu[0])\n",
        "        print(\"------------------------- \\n\")\n",
        "        return model_gpu"
      ],
      "metadata": {
        "id": "T1cPHjxEIT0G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate on TPU Function\n",
        "def train_evaluate_tpu(train_data, train_label, validation_data, validation_label, epochs=500):\n",
        "    print(\"Training and evaluating on TPU:\")\n",
        "    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu_resolver)\n",
        "\n",
        "    with strategy.scope():\n",
        "        model_tpu = build_model()\n",
        "        acc_tpu, loss_tpu = train_model(model_tpu, train_data, train_label, epochs)\n",
        "        print(\"Training Accuracy:\", acc_tpu[-1])\n",
        "        print(\"Training Loss:\", loss_tpu[-1])\n",
        "\n",
        "        result_tpu = evaluate_model(model_tpu, validation_data, validation_label)\n",
        "        print(\"Validation Accuracy:\", result_tpu[1])\n",
        "        print(\"Validation Loss:\", result_tpu[0])\n",
        "        print(\"------------------------- \\n\")\n",
        "        return model_tpu"
      ],
      "metadata": {
        "id": "F1PTkJjcIVi-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model Function\n",
        "def train_model(model, train_data, train_label, epochs=500):\n",
        "    history = model.fit(train_data, train_label, epochs=epochs, verbose=0)\n",
        "    acc = history.history['accuracy']\n",
        "    loss = history.history['loss']\n",
        "    return acc, loss"
      ],
      "metadata": {
        "id": "UaNEG15CIXLF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model Function\n",
        "def evaluate_model(model, validation_data, validation_label):\n",
        "    result = model.evaluate(validation_data, validation_label)\n",
        "    return result"
      ],
      "metadata": {
        "id": "sjS8sJ53IZHN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Data Function\n",
        "def predict_data(model, test_data):\n",
        "    predict = model.predict(test_data)\n",
        "    binary_result = (predict > 0.5).astype(int)\n",
        "    binary_result = binary_result.reshape(test_data.shape[0])\n",
        "    return binary_result"
      ],
      "metadata": {
        "id": "ogEhz_pBIaUu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_dataset(train_data_path, test_data_path):\n",
        "    # Check if files are downloaded, if not, download them\n",
        "    if not os.path.exists(train_data_path) or not os.path.exists(test_data_path):\n",
        "        print(\"Downloading files...\")\n",
        "\n",
        "        # URLs of the dataset files\n",
        "        train_url = \"https://raw.githubusercontent.com/dzaja123/titanic-dataset-CPU-GPU-TPU-evaluation/main/dataset/train.csv\"\n",
        "        test_url = \"https://raw.githubusercontent.com/dzaja123/titanic-dataset-CPU-GPU-TPU-evaluation/main/dataset/test.csv\"\n",
        "\n",
        "        # Download the files\n",
        "        urllib.request.urlretrieve(train_url, train_data_path)\n",
        "        urllib.request.urlretrieve(test_url, test_data_path)"
      ],
      "metadata": {
        "id": "NrYi30Mo7JIz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Function\n",
        "def main():\n",
        "    # Load Data\n",
        "    train_data_path = 'train.csv'\n",
        "    test_data_path = 'test.csv'\n",
        "\n",
        "    # Check if dataset files exist, if not, download them\n",
        "    download_dataset(train_data_path, test_data_path)\n",
        "\n",
        "    train_data = load_data(train_data_path)\n",
        "    test_data = load_data(test_data_path)\n",
        "\n",
        "    # Preprocess Train Data\n",
        "    feature_data = preprocess_data(train_data)\n",
        "\n",
        "    # Split Data\n",
        "    train_data, train_label, validation_data, validation_label = split_data(feature_data)\n",
        "\n",
        "    # Check if running in Colab\n",
        "    try:\n",
        "        in_colab = \"google.colab\" in str(get_ipython())\n",
        "    except:\n",
        "        print(\"Runing the code locally.\")\n",
        "        in_colab = False\n",
        "\n",
        "    # Train and Evaluate based on the available device\n",
        "    if in_colab and (tf.test.gpu_device_name() == \"/device:GPU:0\"):\n",
        "        # Train and Evaluate on GPU\n",
        "        start_time = time.time()\n",
        "        model = train_evaluate_gpu(train_data, train_label, validation_data, validation_label)\n",
        "        training_time = time.time() - start_time\n",
        "        print(\"GPU Training Time:\", training_time)\n",
        "\n",
        "        # Evaluate Inference Time on GPU\n",
        "        start_time = time.time()\n",
        "        _ = predict_data(model, validation_data)\n",
        "        inference_time_gpu = time.time() - start_time\n",
        "        print(\"GPU Inference Time:\", inference_time_gpu)\n",
        "\n",
        "        # Evaluate Memory Usage on GPU\n",
        "        gpu_memory_usage = psutil.virtual_memory().used\n",
        "        print(\"GPU Memory Usage:\", gpu_memory_usage / (1024 * 1024), \"MB\")\n",
        "\n",
        "    elif in_colab and (\"COLAB_TPU_ADDR\" in os.environ):\n",
        "        # Train and Evaluate on TPU\n",
        "        start_time = time.time()\n",
        "        model = train_evaluate_tpu(train_data, train_label, validation_data, validation_label)\n",
        "        training_time = time.time() - start_time\n",
        "        print(\"TPU Training Time:\", training_time)\n",
        "\n",
        "        # Evaluate Inference Time on TPU\n",
        "        start_time = time.time()\n",
        "        _ = predict_data(model, validation_data)\n",
        "        inference_time_tpu = time.time() - start_time\n",
        "        print(\"TPU Inference Time:\", inference_time_tpu)\n",
        "\n",
        "        # Evaluate Memory Usage on TPU\n",
        "        tpu_memory_usage = psutil.virtual_memory().used\n",
        "        print(\"TPU Memory Usage:\", tpu_memory_usage / (1024 * 1024), \"MB\")\n",
        "\n",
        "    else:\n",
        "        # Train and Evaluate on CPU\n",
        "        start_time = time.time()\n",
        "        model = train_evaluate_cpu(train_data, train_label, validation_data, validation_label)\n",
        "        training_time = time.time() - start_time\n",
        "        print(\"CPU Training Time:\", training_time)\n",
        "\n",
        "        # Evaluate Inference Time on CPU\n",
        "        start_time = time.time()\n",
        "        _ = predict_data(model, validation_data)\n",
        "        inference_time_cpu = time.time() - start_time\n",
        "        print(\"CPU Inference Time:\", inference_time_cpu)\n",
        "\n",
        "        # Evaluate Memory Usage on CPU\n",
        "        cpu_memory_usage = psutil.virtual_memory().used\n",
        "        print(\"CPU Memory Usage:\", cpu_memory_usage / (1024 * 1024), \"MB\")\n",
        "\n",
        "    # Preprocess Test Data\n",
        "    test_data_processed = preprocess_data(test_data, is_test=True)\n",
        "    test_data_array = np.array(test_data_processed.iloc[:, 1:])\n",
        "\n",
        "    # Prediction\n",
        "    binary_result = predict_data(model, test_data_array)\n",
        "\n",
        "    # Print predictions\n",
        "    print(\"Predictions: \\n\", binary_result)\n",
        "\n",
        "    # Clear the session to release resources\n",
        "    keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "iDJDdDuKIbvm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore the pandas \"depricated \"warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Md4iNdmVMO0N"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction:**\n",
        "In order to optimize the performance of your notebook, it is crucial to define the hardware accelerator in the notebook settings. This step allows you to harness the power of GPUs (Graphics Processing Units) or TPUs (Tensor Processing Units) for faster computations, especially beneficial for machine learning tasks.\n",
        "\n",
        "**Instructions:**\n",
        "Follow the steps below to set up the hardware accelerator in Google Colab:\n",
        "\n",
        "- Click on the \"Edit -> Notebook settings\" option in the Colab toolbar.\n",
        "- Choose the desired accelerator from the \"Hardware accelerator\" (CPU, GPU or TPU).\n",
        "- Click \"Save\" to apply the changes.\n",
        "\n"
      ],
      "metadata": {
        "id": "GHELV5zgJn0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run the full code, use the \"Runtime -> Run all\" option from the option menu, or use the Ctrl+F9 command from the keyboard."
      ],
      "metadata": {
        "id": "YJFg06B3LI5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGZVPIFHI5x-",
        "outputId": "1aa90e52-0fb2-4ae4-8768-134427702aea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files...\n",
            "Training and evaluating on TPU:\n",
            "Training Accuracy: 0.7715290188789368\n",
            "Training Loss: 0.49968013167381287\n",
            "5/5 [==============================] - 2s 77ms/step - loss: 0.4193 - accuracy: 0.8531\n",
            "Validation Accuracy: 0.8531468510627747\n",
            "Validation Loss: 0.41925570368766785\n",
            "------------------------- \n",
            "\n",
            "TPU Training Time: 123.10009574890137\n",
            "5/5 [==============================] - 1s 85ms/step\n",
            "TPU Inference Time: 1.3607728481292725\n",
            "TPU Memory Usage: 1056.53515625 MB\n",
            "14/14 [==============================] - 1s 12ms/step\n",
            "Predictions: \n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    }
  ]
}